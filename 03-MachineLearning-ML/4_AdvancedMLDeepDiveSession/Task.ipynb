{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b651f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNDERFITTING MODEL:\n",
      "  Train R²: 0.7258\n",
      "  Test R²:  -0.0221\n",
      "\n",
      "OVERFITTING MODEL:\n",
      "  Train R²: 0.9639\n",
      "  Test R²:  0.7913\n",
      "\n",
      "GOOD FIT MODEL:\n",
      "  Train R²: 0.9555\n",
      "  Test R²:  0.8466\n",
      "\n",
      "FIXED MODEL (Regularization):\n",
      "  Train R²: 0.9577\n",
      "  Test R²:  0.8477\n",
      "\n",
      "============================================================\n",
      "SUMMARY TABLE\n",
      "============================================================\n",
      "Model                     Train R²     Test R²      Status\n",
      "------------------------------------------------------------\n",
      "Underfitting (deg=1)      0.7258       -0.0221      _____\n",
      "Overfitting (deg=15)      0.9639       0.7913       _____\n",
      "Good Fit (deg=3)          0.9555       0.8466       _____\n",
      "Fixed (Regularized)       0.9577       0.8477       _____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdo/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.228e+03, tolerance: 2.944e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# STEP 1: Create Dataset\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# Create a CUBIC relationship: y = 0.5x³ - 2x² + 3x + noise\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(50, 1) * 10  # 30 samples\n",
    "\n",
    "# TODO: Create y with cubic pattern + noise (multiply noise by 20)\n",
    "y = 0.5 * X**3 - 2* X**2 + np.random.randn(50,1)*20\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# STEP 2: Create UNDERFITTING Model\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# TODO: Use degree=1 (too simple for cubic data)\n",
    "\n",
    "poly_under = PolynomialFeatures(degree=1)  # YOUR CODE\n",
    "X_train_under = poly_under.fit_transform(X_train) # YOUR CODE\n",
    "X_test_under = poly_under.transform(X_test)   # YOUR CODE\n",
    "\n",
    "model_under = LinearRegression()\n",
    "model_under.fit(X_train_under, y_train)  # YOUR CODE\n",
    "\n",
    "train_r2_under = r2_score(y_train, model_under.predict(X_train_under))\n",
    "test_r2_under = r2_score(y_test, model_under.predict(X_test_under))\n",
    "\n",
    "print(\"UNDERFITTING MODEL:\")\n",
    "print(f\"  Train R²: {train_r2_under:.4f}\")\n",
    "print(f\"  Test R²:  {test_r2_under:.4f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# STEP 3: Create OVERFITTING Model\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# TODO: Use degree=15 (too complex)\n",
    "\n",
    "poly_over = PolynomialFeatures(degree=15)  # YOUR CODE\n",
    "X_train_over = poly_over.fit_transform(X_train)  # YOUR CODE\n",
    "X_test_over = poly_over.transform(X_test)   # YOUR CODE\n",
    "\n",
    "model_over = LinearRegression()\n",
    "model_over.fit(X_train_over, y_train)  # YOUR CODE\n",
    "\n",
    "train_r2_over = r2_score(y_train, model_over.predict(X_train_over))\n",
    "test_r2_over = r2_score(y_test, model_over.predict(X_test_over))\n",
    "\n",
    "print(\"OVERFITTING MODEL:\")\n",
    "print(f\"  Train R²: {train_r2_over:.4f}\")\n",
    "print(f\"  Test R²:  {test_r2_over:.4f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# STEP 4: Create GOOD FIT Model\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# TODO: Use the correct degree for cubic data\n",
    "\n",
    "poly_good = PolynomialFeatures(degree=3)  # YOUR CODE\n",
    "X_train_good = poly_good.fit_transform(X_train)  # YOUR CODE\n",
    "X_test_good = poly_good.transform(X_test)   # YOUR CODE\n",
    "\n",
    "model_good = LinearRegression()\n",
    "model_good.fit(X_train_good, y_train)  # YOUR CODE\n",
    "\n",
    "train_r2_good = r2_score(y_train, model_good.predict(X_train_good))\n",
    "test_r2_good = r2_score(y_test, model_good.predict(X_test_good))\n",
    "\n",
    "print(\"GOOD FIT MODEL:\")\n",
    "print(f\"  Train R²: {train_r2_good:.4f}\")\n",
    "print(f\"  Test R²:  {test_r2_good:.4f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# STEP 5: FIX Overfitting with Regularization\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# TODO: Use Ridge or Lasso with degree=15 to fix overfitting\n",
    "\n",
    "# Use the same poly_over features (degree=15)\n",
    "model_fixed = Lasso(alpha=1)  # YOUR CODE: Ridge or Lasso with appropriate alpha\n",
    "model_fixed.fit(X_train_over , y_train)  # YOUR CODE\n",
    "\n",
    "train_r2_fixed = r2_score(y_train, model_fixed.predict(X_train_over))\n",
    "test_r2_fixed = r2_score(y_test, model_fixed.predict(X_test_over))\n",
    "\n",
    "print(\"FIXED MODEL (Regularization):\")\n",
    "print(f\"  Train R²: {train_r2_fixed:.4f}\")\n",
    "print(f\"  Test R²:  {test_r2_fixed:.4f}\")\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# STEP 6: Create Summary Table\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<25} {'Train R²':<12} {'Test R²':<12} {'Status'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Underfitting (deg=1)':<25} {train_r2_under:<12.4f} {test_r2_under:<12.4f} {'_____'}\")  # Fill status\n",
    "print(f\"{'Overfitting (deg=15)':<25} {train_r2_over:<12.4f} {test_r2_over:<12.4f} {'_____'}\")   # Fill status\n",
    "print(f\"{'Good Fit (deg=3)':<25} {train_r2_good:<12.4f} {test_r2_good:<12.4f} {'_____'}\")       # Fill status\n",
    "print(f\"{'Fixed (Regularized)':<25} {train_r2_fixed:<12.4f} {test_r2_fixed:<12.4f} {'_____'}\") # Fill status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cc5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
