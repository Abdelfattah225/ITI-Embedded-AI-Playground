{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24792a5e",
   "metadata": {},
   "source": [
    " CODE EXAMPLE 1: BAGGING (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce0476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SINGLE DECISION TREE (Baseline)\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 1.000\n",
      "============================================================\n",
      "BAGGING: RANDOM FOREST (10 trees)\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 1.000\n",
      "============================================================\n",
      "BAGGING: Manual BaggingClassifier (10 trees)\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Purchase dataset\n",
    "X = np.array([\n",
    "    [25, 30, 0], [35, 60, 1], [45, 80, 0], [20, 20, 1],\n",
    "    [35, 70, 0], [52, 90, 1], [23, 25, 0], [40, 65, 1],\n",
    "    [30, 45, 1], [50, 85, 0], [28, 35, 1], [42, 75, 0]\n",
    "])\n",
    "y = np.array(['No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# ==========================================\n",
    "# SINGLE DECISION TREE (Baseline)\n",
    "# ==========================================\n",
    "single_tree = DecisionTreeClassifier(random_state=42)\n",
    "single_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SINGLE DECISION TREE (Baseline)\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, single_tree.predict(X_train)):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, single_tree.predict(X_test)):.3f}\")\n",
    "\n",
    "# ==========================================\n",
    "# BAGGING: Random Forest\n",
    "# ==========================================\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=10,      # Number of trees\n",
    "    max_depth=3,          # Depth of each tree\n",
    "    random_state=42\n",
    ")\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BAGGING: RANDOM FOREST (10 trees)\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, random_forest.predict(X_train)):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, random_forest.predict(X_test)):.3f}\")\n",
    "\n",
    "# ==========================================\n",
    "# BAGGING: Manual (with any classifier)\n",
    "# ==========================================\n",
    "bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=3),\n",
    "    n_estimators=10,      # Number of models\n",
    "    random_state=42\n",
    ")\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BAGGING: Manual BaggingClassifier (10 trees)\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, bagging.predict(X_train)):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, bagging.predict(X_test)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e774343",
   "metadata": {},
   "source": [
    "ðŸ’» CODE EXAMPLE 2: BOOSTING (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb56579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BOOSTING: AdaBoost (10 rounds)\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 1.000\n",
      "============================================================\n",
      "BOOSTING: Gradient Boosting (10 rounds)\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 1.000\n",
      "\n",
      "============================================================\n",
      "COMPARISON SUMMARY:\n",
      "Model                     Train Acc    Test Acc    \n",
      "------------------------------------------------------------\n",
      "Single Tree               1.000        1.000       \n",
      "Random Forest (Bagging)   1.000        1.000       \n",
      "AdaBoost                  1.000        1.000       \n",
      "Gradient Boosting         1.000        1.000       \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "# ==========================================\n",
    "# BOOSTING: AdaBoost\n",
    "# ==========================================\n",
    "adaboost = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),  # Weak learner\n",
    "    n_estimators=10,      # Number of boosting rounds\n",
    "    random_state=42\n",
    ")\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BOOSTING: AdaBoost (10 rounds)\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, adaboost.predict(X_train)):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, adaboost.predict(X_test)):.3f}\")\n",
    "\n",
    "# ==========================================\n",
    "# BOOSTING: Gradient Boosting\n",
    "# ==========================================\n",
    "gradient_boost = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,    # How much each model contributes\n",
    "    random_state=42\n",
    ")\n",
    "gradient_boost.fit(X_train, y_train)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BOOSTING: Gradient Boosting (10 rounds)\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, gradient_boost.predict(X_train)):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, gradient_boost.predict(X_test)):.3f}\")\n",
    "\n",
    "# ==========================================\n",
    "# COMPARISON\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON SUMMARY:\")\n",
    "print(f\"{'Model':<25} {'Train Acc':<12} {'Test Acc':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "models = {\n",
    "    'Single Tree': single_tree,\n",
    "    'Random Forest (Bagging)': random_forest,\n",
    "    'AdaBoost': adaboost,\n",
    "    'Gradient Boosting': gradient_boost\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"{name:<25} {train_acc:<12.3f} {test_acc:<12.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b48d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
